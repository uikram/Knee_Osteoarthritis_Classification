{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì OpenAI available\n",
      "OpenAI API Key set: True\n",
      "GPT Model: gpt-4o\n",
      "\n",
      "================================================================================\n",
      "Testing GPT-4 Report Generator Initialization\n",
      "================================================================================\n",
      "‚úì Initialized GPT-4 (gpt-4o) with temperature=0.3\n",
      "‚úÖ GPT-4 Report Generator ready!\n",
      "   Model: gpt-4o\n",
      "   Temperature: 0.3\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Quick Copy-Paste Version - GPT-4 LLM Report Generator\n",
    "# Just copy this entire cell to your notebook\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6'\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# OpenAI API for LLM\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    OPENAI_AVAILABLE = True\n",
    "    print(\"‚úì OpenAI available\")\n",
    "except ImportError:\n",
    "    OPENAI_AVAILABLE = False\n",
    "    print(\"‚ùå Install: pip install openai\")\n",
    "\n",
    "#=============================================================================\n",
    "# CONFIGURATION\n",
    "#=============================================================================\n",
    "\n",
    "class LLMConfig:\n",
    "    \"\"\"Configuration for LLM Report Generation\"\"\"\n",
    "    \n",
    "    # API Configuration - HARDCODED (Change this to your new key!)\n",
    "    openai_api_key = \"OPEN_AI_API\"  # ‚Üê PUT YOUR NEW KEY HERE\n",
    "    \n",
    "    # Output settings\n",
    "    output_dir = \"./medical_reports\"\n",
    "    num_samples = 5\n",
    "    \n",
    "    # Model to use (can override XAI config)\n",
    "    model_to_use = {\n",
    "        'name': 'densenet_161',\n",
    "        'size': 224,\n",
    "        'folder': '(224, 224)'\n",
    "    }\n",
    "    fold_to_analyze = 1\n",
    "    \n",
    "    # GPT Model Configuration\n",
    "    gpt_model = 'gpt-4o'  # Options: 'gpt-4o', 'gpt-4-turbo', 'gpt-4'\n",
    "    temperature = 0.3\n",
    "\n",
    "llm_config = LLMConfig()\n",
    "\n",
    "print(f\"OpenAI API Key set: {bool(llm_config.openai_api_key)}\")\n",
    "print(f\"GPT Model: {llm_config.gpt_model}\")\n",
    "\n",
    "#=============================================================================\n",
    "# GRAD-CAM ATTENTION ANALYSIS\n",
    "#=============================================================================\n",
    "\n",
    "def analyze_gradcam_for_prompt(cam: np.ndarray) -> Dict:\n",
    "    \"\"\"Analyze Grad-CAM heatmap for LLM prompt\"\"\"\n",
    "    threshold = np.percentile(cam, 75)\n",
    "    high_attention = cam > threshold\n",
    "    \n",
    "    attention_stats = {\n",
    "        'mean_activation': float(cam.mean()),\n",
    "        'max_activation': float(cam.max()),\n",
    "        'attention_coverage': float(high_attention.sum() / high_attention.size),\n",
    "        'attention_regions': []\n",
    "    }\n",
    "    \n",
    "    # Divide into anatomical regions\n",
    "    h, w = cam.shape\n",
    "    regions = {\n",
    "        'upper_medial': cam[:h//2, :w//2],\n",
    "        'upper_lateral': cam[:h//2, w//2:],\n",
    "        'lower_medial': cam[h//2:, :w//2],\n",
    "        'lower_lateral': cam[h//2:, w//2:],\n",
    "        'central_joint': cam[h//4:3*h//4, w//4:3*w//4]\n",
    "    }\n",
    "    \n",
    "    for region_name, region_data in regions.items():\n",
    "        region_mean = float(region_data.mean())\n",
    "        if region_mean > attention_stats['mean_activation']:\n",
    "            attention_stats['attention_regions'].append({\n",
    "                'region': region_name.replace('_', ' ').title(),\n",
    "                'activation': region_mean\n",
    "            })\n",
    "    \n",
    "    attention_stats['attention_regions'].sort(key=lambda x: x['activation'], reverse=True)\n",
    "    return attention_stats\n",
    "\n",
    "#=============================================================================\n",
    "# GPT-4 MEDICAL REPORT GENERATOR\n",
    "#=============================================================================\n",
    "\n",
    "class MedicalReportGenerator:\n",
    "    \"\"\"Generate medical reports using GPT-4 Vision API\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = 'gpt-4o', temperature: float = 0.3, api_key: str = None):\n",
    "        \"\"\"\n",
    "        Initialize GPT-4 based medical report generator\n",
    "        \n",
    "        Args:\n",
    "            model: GPT model ('gpt-4o', 'gpt-4-turbo', 'gpt-4')\n",
    "            temperature: Generation temperature (0.0 - 1.0)\n",
    "            api_key: OpenAI API key (or uses OPENAI_API_KEY env)\n",
    "        \"\"\"\n",
    "        if not OPENAI_AVAILABLE:\n",
    "            raise ImportError(\"Install: pip install openai\")\n",
    "        \n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        print(f\"‚úì Initialized GPT-4 ({model}) with temperature={temperature}\")\n",
    "    \n",
    "    def image_to_base64(self, image: np.ndarray) -> str:\n",
    "        \"\"\"Convert numpy image to base64\"\"\"\n",
    "        pil_image = Image.fromarray(image)\n",
    "        buffer = BytesIO()\n",
    "        pil_image.save(buffer, format='PNG')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "    \n",
    "    def generate_report(\n",
    "        self,\n",
    "        original_image: np.ndarray,\n",
    "        gradcam_image: np.ndarray,\n",
    "        prediction: int,\n",
    "        confidence: float,\n",
    "        all_probs: np.ndarray,\n",
    "        attention_analysis: Dict,\n",
    "        class_names: list,\n",
    "        grade_descriptions: dict,\n",
    "        true_label: Optional[int] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Generate comprehensive medical report using GPT-4 Vision\"\"\"\n",
    "        \n",
    "        # Encode images\n",
    "        original_b64 = self.image_to_base64(original_image)\n",
    "        gradcam_b64 = self.image_to_base64(gradcam_image)\n",
    "        \n",
    "        # Format probability distribution\n",
    "        prob_text = \"\\n\".join([\n",
    "            f\"  - {class_names[i]}: {prob:.1%}\"\n",
    "            for i, prob in enumerate(all_probs)\n",
    "        ])\n",
    "        \n",
    "        # Format attention regions\n",
    "        attention_text = \"\\n\".join([\n",
    "            f\"  - {region['region']}: Activation {region['activation']:.3f}\"\n",
    "            for region in attention_analysis['attention_regions'][:3]\n",
    "        ]) if attention_analysis['attention_regions'] else \"  - Distributed attention\"\n",
    "        \n",
    "        # Build prompt\n",
    "        prompt = f\"\"\"You are an expert radiologist assistant analyzing knee X-ray images for osteoarthritis classification using an AI model.\n",
    "\n",
    "**Model Prediction:**\n",
    "- Predicted Grade: {class_names[prediction]}\n",
    "- Confidence: {confidence:.1%}\n",
    "- Clinical Description: {grade_descriptions.get(prediction, 'N/A')}\n",
    "\n",
    "**Probability Distribution:**\n",
    "{prob_text}\n",
    "\n",
    "**Grad-CAM Attention Analysis:**\n",
    "The model focused on these regions when making its decision:\n",
    "- Overall attention strength: {attention_analysis['mean_activation']:.3f}\n",
    "- Peak activation: {attention_analysis['max_activation']:.3f}\n",
    "- Coverage of high-attention areas: {attention_analysis['attention_coverage']:.1%}\n",
    "\n",
    "Primary regions of interest:\n",
    "{attention_text}\n",
    "\n",
    "{f\"**Ground Truth Label:** {class_names[true_label]}\" if true_label is not None else \"\"}\n",
    "\n",
    "**Task:**\n",
    "Generate a professional medical report with these sections:\n",
    "\n",
    "1. **CLINICAL IMPRESSION**\n",
    "   - State the AI-predicted osteoarthritis grade\n",
    "   - Assess confidence level and clinical significance\n",
    "\n",
    "2. **RADIOLOGICAL FINDINGS**\n",
    "   - Describe what anatomical features the AI focused on (based on Grad-CAM regions)\n",
    "   - Interpret attention patterns in clinical terms\n",
    "   - Mention relevant structures: joint space, osteophytes, bone margins, sclerosis\n",
    "\n",
    "3. **AI MODEL INTERPRETATION**\n",
    "   - Explain WHY the model focused on specific regions\n",
    "   - Connect attention patterns to known OA features\n",
    "   - Discuss if the AI's focus aligns with clinical practice\n",
    "\n",
    "4. **CONFIDENCE ANALYSIS**\n",
    "   - If confidence is low (<70%), discuss alternative diagnoses\n",
    "   - Note any ambiguous features or borderline findings\n",
    "\n",
    "5. **RECOMMENDATIONS**\n",
    "   - Clinical correlation advised (standard disclaimer)\n",
    "   - Suggest follow-up if appropriate\n",
    "   - Note AI limitations\n",
    "\n",
    "**Guidelines:**\n",
    "- Keep report concise (300-400 words)\n",
    "- Use professional medical terminology\n",
    "- Translate AI insights into clinically meaningful observations\n",
    "- Be honest about model limitations\n",
    "- Focus on what the attention map reveals about the decision-making process\n",
    "\n",
    "Generate the report now:\"\"\"\n",
    "\n",
    "        # Call GPT-4 Vision API\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=2000,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": prompt\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/png;base64,{original_b64}\",\n",
    "                                    \"detail\": \"high\"\n",
    "                                }\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/png;base64,{gradcam_b64}\",\n",
    "                                    \"detail\": \"high\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Error generating report: {str(e)}\\n\\nPlease check your API key and internet connection.\"\n",
    "\n",
    "#=============================================================================\n",
    "# TEST INITIALIZATION\n",
    "#=============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Testing GPT-4 Report Generator Initialization\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if llm_config.openai_api_key:\n",
    "    try:\n",
    "        # IMPORTANT: Pass API key explicitly to the generator\n",
    "        report_generator = MedicalReportGenerator(\n",
    "            model=llm_config.gpt_model,\n",
    "            temperature=llm_config.temperature,\n",
    "            api_key=llm_config.openai_api_key  # This is the critical line!\n",
    "        )\n",
    "        print(\"‚úÖ GPT-4 Report Generator ready!\")\n",
    "        print(f\"   Model: {llm_config.gpt_model}\")\n",
    "        print(f\"   Temperature: {llm_config.temperature}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize: {e}\")\n",
    "        print(f\"   Check your API key is valid\")\n",
    "        report_generator = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è OPENAI_API_KEY not set. Set via:\")\n",
    "    print(\"   export OPENAI_API_KEY='your-key'\")\n",
    "    print(\"   OR set it directly in the notebook:\")\n",
    "    print(\"   llm_config.openai_api_key = 'your-key-here'\")\n",
    "    report_generator = None\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usama/anaconda3/envs/analysis/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Output directory: ./xai_visualizations\n",
      "CUDA available: True\n",
      "================================================================================\n",
      "                    ü§ñ GENERATING GPT-4 MEDICAL REPORTS\n",
      "================================================================================\n",
      "\n",
      "üìä Loading test data from: ../KneeXray/test/test_correct.csv\n",
      "‚úì Total samples available: 1656\n",
      "\n",
      "üéØ Processing 5 samples...\n",
      "\n",
      "üîß Loading model: densenet_161...\n",
      "   Loading: 1fold_epoch8.pt\n",
      "   From: ./models/densenet_161/(224, 224)/1fold_epoch8.pt\n",
      "   ‚úì Successfully loaded: 1fold_epoch8.pt\n",
      "‚úì Model loaded\n",
      "\n",
      "================================================================================\n",
      "[1/5] 9946846R.png\n",
      "Ground Truth: Grade 4\n",
      "================================================================================\n",
      "üìÅ Loading image...\n",
      "üîç Generating Grad-CAM...\n",
      "   Prediction: Grade 4 (52.3%)\n",
      "üìä Analyzing attention patterns...\n",
      "‚úçÔ∏è  Generating medical report with GPT-4...\n",
      "   ‚úì Saved visualization: report_01_9946846R.png\n",
      "   ‚úì Saved text report: report_01_9946846R.txt\n",
      "‚úÖ Sample 1 completed successfully\n",
      "\n",
      "================================================================================\n",
      "[2/5] 9283061L.png\n",
      "Ground Truth: Grade 0\n",
      "================================================================================\n",
      "üìÅ Loading image...\n",
      "üîç Generating Grad-CAM...\n",
      "   Prediction: Grade 0 (72.5%)\n",
      "üìä Analyzing attention patterns...\n",
      "‚úçÔ∏è  Generating medical report with GPT-4...\n",
      "   ‚úì Saved visualization: report_02_9283061L.png\n",
      "   ‚úì Saved text report: report_02_9283061L.txt\n",
      "‚úÖ Sample 2 completed successfully\n",
      "\n",
      "================================================================================\n",
      "[3/5] 9460225L.png\n",
      "Ground Truth: Grade 1\n",
      "================================================================================\n",
      "üìÅ Loading image...\n",
      "üîç Generating Grad-CAM...\n",
      "   Prediction: Grade 0 (61.3%)\n",
      "üìä Analyzing attention patterns...\n",
      "‚úçÔ∏è  Generating medical report with GPT-4...\n",
      "   ‚úì Saved visualization: report_03_9460225L.png\n",
      "   ‚úì Saved text report: report_03_9460225L.txt\n",
      "‚úÖ Sample 3 completed successfully\n",
      "\n",
      "================================================================================\n",
      "[4/5] 9712419L.png\n",
      "Ground Truth: Grade 0\n",
      "================================================================================\n",
      "üìÅ Loading image...\n",
      "üîç Generating Grad-CAM...\n",
      "   Prediction: Grade 0 (78.5%)\n",
      "üìä Analyzing attention patterns...\n",
      "‚úçÔ∏è  Generating medical report with GPT-4...\n",
      "   ‚úì Saved visualization: report_04_9712419L.png\n",
      "   ‚úì Saved text report: report_04_9712419L.txt\n",
      "‚úÖ Sample 4 completed successfully\n",
      "\n",
      "================================================================================\n",
      "[5/5] 9786263R.png\n",
      "Ground Truth: Grade 2\n",
      "================================================================================\n",
      "üìÅ Loading image...\n",
      "üîç Generating Grad-CAM...\n",
      "   Prediction: Grade 0 (42.7%)\n",
      "üìä Analyzing attention patterns...\n",
      "‚úçÔ∏è  Generating medical report with GPT-4...\n",
      "   ‚úì Saved visualization: report_05_9786263R.png\n",
      "   ‚úì Saved text report: report_05_9786263R.txt\n",
      "‚úÖ Sample 5 completed successfully\n",
      "\n",
      "================================================================================\n",
      "üìä PROCESSING SUMMARY\n",
      "================================================================================\n",
      "‚úÖ Successful: 5/5\n",
      "\n",
      "üìÅ Reports saved to: ./medical_reports\n",
      "   - 5 PNG visualizations\n",
      "   - 5 TXT reports\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Process Multiple Samples - Generate GPT-4 Medical Reports\n",
    "# Copy this cell to your notebook (after initializing GPT-4 generator)\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from xai import (\n",
    "    XAIConfig,\n",
    "    ImageDataset,\n",
    "    create_model,\n",
    "    get_target_layer,\n",
    "    load_model_weights,\n",
    "    generate_gradcam,\n",
    "    generate_lime_explanation,\n",
    "    create_comprehensive_xai_visualization,\n",
    "    select_samples_for_visualization,\n",
    "    \n",
    ")\n",
    "config = XAIConfig()\n",
    "def create_report_visualization(\n",
    "    original_image,\n",
    "    gradcam_image,\n",
    "    prediction,\n",
    "    confidence,\n",
    "    all_probs,\n",
    "    report,\n",
    "    save_path,\n",
    "    class_names,\n",
    "    true_label=None\n",
    "):\n",
    "    \"\"\"Create comprehensive visualization with LLM report\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    gs = fig.add_gridspec(3, 3, height_ratios=[1, 1, 1.2], hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # Row 1: Original Image\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(original_image)\n",
    "    title = 'Original Knee X-ray'\n",
    "    if true_label is not None:\n",
    "        title += f'\\nGround Truth: {class_names[true_label]}'\n",
    "    ax1.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Row 1: Grad-CAM Visualization\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(gradcam_image)\n",
    "    ax2.set_title(f'AI Attention Map (Grad-CAM)\\nPrediction: {class_names[prediction]}',\n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Row 1: Probability Distribution\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    colors = ['#27ae60' if i == prediction else '#3498db' for i in range(len(class_names))]\n",
    "    bars = ax3.barh(class_names, all_probs, color=colors)\n",
    "    ax3.set_xlabel('Confidence', fontsize=10)\n",
    "    ax3.set_title(f'Class Probabilities\\nMax: {confidence:.1%}', fontsize=12, fontweight='bold')\n",
    "    ax3.set_xlim([0, 1])\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    for i, (bar, prob) in enumerate(zip(bars, all_probs)):\n",
    "        ax3.text(prob + 0.02, i, f'{prob:.1%}', va='center', fontsize=9)\n",
    "    \n",
    "    # Row 2 & 3: Medical Report (spans full width)\n",
    "    ax4 = fig.add_subplot(gs[1:, :])\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Report header\n",
    "    ax4.text(0.5, 0.98, 'üè• GPT-4 GENERATED MEDICAL REPORT',\n",
    "             fontsize=16, fontweight='bold', ha='center', va='top', \n",
    "             transform=ax4.transAxes,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.3))\n",
    "    \n",
    "    # Report content\n",
    "    report_formatted = report.replace('**', '')\n",
    "    ax4.text(0.02, 0.90, report_formatted,\n",
    "             fontsize=9.5, va='top', wrap=True, transform=ax4.transAxes,\n",
    "             family='serif',\n",
    "             bbox=dict(boxstyle='round,pad=1', facecolor='#f9f9f9', \n",
    "                      edgecolor='gray', linewidth=1.5, alpha=0.8))\n",
    "    \n",
    "    # Footer disclaimer\n",
    "    disclaimer = (\"‚ö†Ô∏è DISCLAIMER: This is an AI-generated report for research purposes only. \"\n",
    "                 \"All findings must be verified by a qualified radiologist before clinical use.\")\n",
    "    ax4.text(0.5, 0.01, disclaimer,\n",
    "             fontsize=8, ha='center', va='bottom', transform=ax4.transAxes,\n",
    "             style='italic', color='red', weight='bold')\n",
    "    \n",
    "    # Overall title\n",
    "    correct_symbol = '‚úÖ' if (true_label is not None and prediction == true_label) else '‚ùå' if true_label is not None else ''\n",
    "    fig.suptitle(f'Knee Osteoarthritis AI Classification Report {correct_symbol}',\n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"   ‚úì Saved visualization: {os.path.basename(save_path)}\")\n",
    "\n",
    "\n",
    "def process_multiple_samples(num_samples=5):\n",
    "    \"\"\"\n",
    "    Process multiple samples and generate GPT-4 medical reports\n",
    "    \n",
    "    Args:\n",
    "        num_samples: Number of samples to process\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\" \"*20 + \"ü§ñ GENERATING GPT-4 MEDICAL REPORTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Check if report_generator is initialized\n",
    "    if 'report_generator' not in globals() or report_generator is None:\n",
    "        print(\"\\n‚ùå Error: report_generator not initialized!\")\n",
    "        print(\"Please run the GPT-4 initialization cell first.\")\n",
    "        return\n",
    "    \n",
    "    # Load test data\n",
    "    print(f\"\\nüìä Loading test data from: {config.test_csv}\")\n",
    "    test_df = pd.read_csv(config.test_csv)\n",
    "    print(f\"‚úì Total samples available: {len(test_df)}\")\n",
    "    \n",
    "    # Select samples (random or stratified)\n",
    "    samples = test_df.sample(n=min(num_samples, len(test_df)), random_state=42)\n",
    "    print(f\"\\nüéØ Processing {len(samples)} samples...\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"üîß Loading model: {llm_config.model_to_use['name']}...\")\n",
    "    model, model_name = load_model_weights(llm_config.model_to_use, fold=llm_config.fold_to_analyze)\n",
    "    target_layer = get_target_layer(model, model_name)\n",
    "    print(f\"‚úì Model loaded\\n\")\n",
    "    \n",
    "    # Image preprocessing\n",
    "    img_size = llm_config.model_to_use['size']\n",
    "    transform = A.Compose([\n",
    "        A.Resize(img_size, img_size, interpolation=cv2.INTER_CUBIC),\n",
    "        A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    # Process each sample\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for idx, (_, row) in enumerate(samples.iterrows(), 1):\n",
    "        img_path = row['data']\n",
    "        true_label = row['label']\n",
    "        \n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"[{idx}/{len(samples)}] {os.path.basename(img_path)}\")\n",
    "        print(f\"Ground Truth: {config.class_names[true_label]}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            # Load image\n",
    "            print(\"üìÅ Loading image...\")\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to load image: {img_path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Prepare image\n",
    "            image_resized = cv2.resize(image, (img_size, img_size))\n",
    "            image_np = image_resized.astype(np.float32) / 255.0\n",
    "            augmented = transform(image=image)\n",
    "            img_tensor = augmented['image']\n",
    "            \n",
    "            # Generate Grad-CAM\n",
    "            print(\"üîç Generating Grad-CAM...\")\n",
    "            cam, prediction, confidence = generate_gradcam(\n",
    "                model, img_tensor, target_layer, method='gradcam'\n",
    "            )\n",
    "            \n",
    "            # Get all probabilities\n",
    "            with torch.no_grad():\n",
    "                input_tensor = img_tensor.unsqueeze(0).to(config.device)\n",
    "                output = model(input_tensor)\n",
    "                all_probs = torch.nn.functional.softmax(output, dim=1)[0].cpu().numpy()\n",
    "            \n",
    "            # Create Grad-CAM visualization\n",
    "            gradcam_img = show_cam_on_image(image_np, cam, use_rgb=True)\n",
    "            \n",
    "            print(f\"   Prediction: {config.class_names[prediction]} ({confidence:.1%})\")\n",
    "            \n",
    "            # Analyze attention patterns\n",
    "            print(\"üìä Analyzing attention patterns...\")\n",
    "            attention_analysis = analyze_gradcam_for_prompt(cam)\n",
    "            \n",
    "            # Generate medical report with GPT-4\n",
    "            print(\"‚úçÔ∏è  Generating medical report with GPT-4...\")\n",
    "            report = report_generator.generate_report(\n",
    "                image_resized,\n",
    "                gradcam_img,\n",
    "                prediction,\n",
    "                confidence,\n",
    "                all_probs,\n",
    "                attention_analysis,\n",
    "                config.class_names,\n",
    "                config.grade_descriptions,\n",
    "                true_label\n",
    "            )\n",
    "        \n",
    "            # Save visualization\n",
    "            save_path = os.path.join(\n",
    "                llm_config.output_dir,\n",
    "                f\"report_{idx:02d}_{os.path.basename(img_path)}\"\n",
    "            )\n",
    "            \n",
    "            create_report_visualization(\n",
    "                image_resized,\n",
    "                gradcam_img,\n",
    "                prediction,\n",
    "                confidence,\n",
    "                all_probs,\n",
    "                report,\n",
    "                save_path,\n",
    "                config.class_names,\n",
    "                true_label\n",
    "            )\n",
    "            \n",
    "            # Save text report\n",
    "            report_txt = save_path.replace('.png', '.txt')\n",
    "            with open(report_txt, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"KNEE OSTEOARTHRITIS AI CLASSIFICATION REPORT\\n\")\n",
    "                f.write(\"=\"*80 + \"\\n\\n\")\n",
    "                f.write(f\"Patient Case ID: {os.path.basename(img_path)}\\n\")\n",
    "                f.write(f\"Ground Truth: {config.class_names[true_label]}\\n\")\n",
    "                f.write(f\"AI Prediction: {config.class_names[prediction]} (Confidence: {confidence:.1%})\\n\")\n",
    "                f.write(f\"\\nModel: {model_name}\\n\")\n",
    "                f.write(f\"Fold: {llm_config.fold_to_analyze}\\n\")\n",
    "                f.write(f\"\\n{'='*80}\\n\\n\")\n",
    "                f.write(report)\n",
    "                f.write(f\"\\n\\n{'='*80}\\n\")\n",
    "                f.write(\"TECHNICAL DETAILS\\n\")\n",
    "                f.write(\"=\"*80 + \"\\n\")\n",
    "                f.write(f\"Attention Coverage: {attention_analysis['attention_coverage']:.1%}\\n\")\n",
    "                f.write(f\"Mean Activation: {attention_analysis['mean_activation']:.3f}\\n\")\n",
    "                f.write(f\"Max Activation: {attention_analysis['max_activation']:.3f}\\n\")\n",
    "                if attention_analysis['attention_regions']:\n",
    "                    f.write(\"\\nTop Attention Regions:\\n\")\n",
    "                    for region in attention_analysis['attention_regions'][:3]:\n",
    "                        f.write(f\"  - {region['region']}: {region['activation']:.3f}\\n\")\n",
    "            \n",
    "            print(f\"   ‚úì Saved text report: {os.path.basename(report_txt)}\")\n",
    "            print(f\"‚úÖ Sample {idx} completed successfully\\n\")\n",
    "            successful += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing sample {idx}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            failed += 1\n",
    "            print()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"=\"*80)\n",
    "    print(\"üìä PROCESSING SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"‚úÖ Successful: {successful}/{len(samples)}\")\n",
    "    if failed > 0:\n",
    "        print(f\"‚ùå Failed: {failed}/{len(samples)}\")\n",
    "    print(f\"\\nüìÅ Reports saved to: {llm_config.output_dir}\")\n",
    "    print(f\"   - {successful} PNG visualizations\")\n",
    "    print(f\"   - {successful} TXT reports\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# RUN THE PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\" or True:  # Works in both script and notebook\n",
    "    # Process 5 samples (change this number as needed)\n",
    "    process_multiple_samples(num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (analysis)",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
